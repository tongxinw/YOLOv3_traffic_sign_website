---
layout: post
title: Midway Blog Post
bigimg: /img/darknet.jpg
gh-repo: https://github.com/tongxinw/YOLOv3_traffic_sign
tags: [traffic sign, yolov3, object detection]
comments: true
---

# Building Darknet and Loading Pretrained Weights


The new network in YOLOv3, Darknet-53, is based on Darknet-19, which is used in YOLOv2, combining with the concept from residual networks. It includes shortcuts connections with more fine-grained information, which performs as a better feature extractor. Also, it has upsampling layers merging with previous feature maps to get more meaningful information. In total, it has 106 layers to perform as a good object detector. We still use Google Colab with free GPUs as our cloud platform. We cloned the darknet from [AlexeyAB’s GitHub repository](https://github.com/AlexeyAB/darknet), adjusted it to enable GPU, and then built the network. Since YOLOv3 has already been trained on the COCO dataset with 80 classes, we just loaded the pretrained weights from the [official website](https://pjreddie.com/media/files/yolov3.weights) so that we do not have to train the huge network from scratch and hopefully reduce the training time.

# Gathering a Custom Dataset and Preparations for Training

As we have mentioned in our initial blog post, we collected images with annotations from Google’s Open Images Dataset V6 and decided to train our own detector with a new class, which is traffic signs. Every single image comes with a .txt file annotating coordinates of the boundary, the height and the width of the object. The figure below is obtained from [AlexeyAB’s GitHub repository](https://github.com/AlexeyAB/darknet) which explains the annotation for the training set.

<div style="text-align:center;">
  <img src="https://miro.medium.com/max/1400/1*5Ok-XrHyu3qBzwGPEi3-bA.png" alt="annotation">
  <em>Source: AlexeyAB’s GitHub repository</em>
</div>
<br/>

We copied over the configuration file of YOLOv3 and made some modifications according to our new single class detector. We made the maximum number of batches to be 2000 per class, which should be 2000 in this case. The number of steps are respectively 80% and 90% percent of the number of batches to make sure it iterates enough, thus we have 1600 and 1800 for steps. Since YOLOv3 predicts bounding boxes at 3 different scales, the last of convolutional layers of every feature extractor block predicts a 3-d tensor encoding bounding box, objectness, and class predictions. In total, the tensor is N * N * ((4+1+1) * 3) for the 4 bounding box offsets (manifested in annotations), 1 objectness detection (confidence level), and 1 class prediction. Thus the number of filters, which is the same as the number of feature maps, is 18 in this case. Before running the config files, the number of classes is set to one for each of the 3 yolo layers performing bounding box prediction, while the number of filters should be 18 for each convolutional layer before it.

To determine the bounding box priors, YOLOv3 still uses k-means clustering. In this case, we just chose 9 clusters which are shown as anchors and 3 scales arbitrarily and then divided them evenly across scales. Here are the parameters of one of the yolo layers and one convolutional layer above it in the configuration file.

<div style="text-align:center;">
  <img src="https://miro.medium.com/max/1400/1*_vEBoR5t48PbBlg0SYTg-w.png" alt="config">
</div>
<br/>

Besides, obj.names and obj.data should be modified based on the target class(es) we want to train. In this case, we would include one class name as “traffic sign” and set up the number of classes as one in the obj.data file.

Considering there might be automatic interruption in Colab, we would like to take advantage of the backup folder specified in the obj.data file. The program would save current weights in the backup folder after training about every other 40 images.

# Training the Custom Object Detector

With all the previous preparations, we are ready to train the detector. Our training dataset has over 2818 images of traffic signs, and it takes about 4–6 hours to train the customized detector. Here is a plot showing the loss through the training process:

<div style="text-align:center;">
  <img src="https://miro.medium.com/max/1400/1*BnRXb2R22IDazgy_sBrICQ.png" alt="loss">
</div>

We can see that over 400 iterations, the average loss has been reduced to lower than 2, which indicates an accurate model. In the end, the average loss is lower than 0.5.

Although the original YOLOv3 is able to detect stop signs, it is unable to detect traffic signs other than stop signs since they are not in the 80 classes it has been trained. Now we are happy to see traffic signs can be detected with our own detector!

<div style="text-align:center;">
  <img src="https://miro.medium.com/max/1400/1*9Aeuaxp7nGYaRxOJz4I7Pw.png" alt="test">
  <em>Source: Google</em>
</div>

# References

[AlexeyAB’s GitHub repository](https://github.com/AlexeyAB/darknet)

[YOLOv3 official website](https://pjreddie.com/media/files/yolov3.weights)

[Useful YouTube video](https://www.youtube.com/watch?v=10joRJt39Ns&t=1138s)


